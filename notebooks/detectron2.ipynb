{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "supreme-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data as data_utils\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "import albumentations as A\n",
    "# import albumentations_experimental as AE\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random, sys\n",
    "import pandas as pd\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "# Connect your script to Neptune\n",
    "# import neptune\n",
    "# import neptune_config\n",
    "\n",
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "southern-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(DefaultTrainer):\n",
    "    \"\"\"\n",
    "    We use the \"DefaultTrainer\" which contains a number pre-defined logic for\n",
    "    standard training workflow. They may not work for you, especially if you\n",
    "    are working on a new research project. In that case you can use the cleaner\n",
    "    \"SimpleTrainer\", or write your own training loop.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        \"\"\"\n",
    "        Create evaluator(s) for a given dataset.\n",
    "        This uses the special metadata \"evaluator_type\" associated with each builtin dataset.\n",
    "        For your own dataset, you can simply create an evaluator manually in your\n",
    "        script and do not have to worry about the hacky if-else logic here.\n",
    "        \"\"\"\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        evaluator_list = []\n",
    "        evaluator_type = MetadataCatalog.get(dataset_name).evaluator_type\n",
    "        if evaluator_type in [\"coco\", \"coco_panoptic_seg\"]:\n",
    "            evaluator_list.append(COCOEvaluator(dataset_name, cfg, True, output_folder))\n",
    "        if len(evaluator_list) == 0:\n",
    "            raise NotImplementedError(\n",
    "                \"no Evaluator for the dataset {} with the type {}\".format(\n",
    "                    dataset_name, evaluator_type\n",
    "                )\n",
    "            )\n",
    "        if len(evaluator_list) == 1:\n",
    "            return evaluator_list[0]\n",
    "        return DatasetEvaluators(evaluator_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fiscal-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(imgs, keypoints, random_state=42):\n",
    "    d = dict()\n",
    "    for file in imgs:\n",
    "        key = ''.join(file.split('-')[:-1])\n",
    "        if key not in d.keys():\n",
    "            d[key] = [file]\n",
    "        else:\n",
    "            d[key].append(file)\n",
    "            \n",
    "    np.random.seed(random_state)\n",
    "    trains = []\n",
    "    validations = []\n",
    "    for key, value in d.items():\n",
    "        r = np.random.randint(len(value), size=2)\n",
    "        for i in range(len(value)):\n",
    "            if i in r:\n",
    "                validations.append(np.where(imgs == value[i])[0][0])\n",
    "            else:\n",
    "                trains.append(np.where(imgs == value[i])[0][0])\n",
    "    return (\n",
    "        imgs[trains], imgs[validations],\n",
    "        keypoints[trains], keypoints[validations]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "satellite-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split2(augmented, train):\n",
    "    train_imgs = train.iloc[:, 0].to_numpy()\n",
    "    train_keypoints = train.iloc[:, 1:].to_numpy()\n",
    "    aug_imgs = augmented.iloc[:, 0].to_numpy()\n",
    "    aug_keypoints = augmented.iloc[:, 1:].to_numpy()\n",
    "    return aug_imgs, train_imgs, aug_keypoints, train_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "assigned-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dicts(data_dir, imgs, keypoints, phase):\n",
    "#     train_dir = os.path.join(data_dir, \"augmented\" if phase==\"train\" else \"train_imgs\")\n",
    "    train_dir = os.path.join(data_dir, \"train_imgs\")\n",
    "    dataset_dicts = []\n",
    "\n",
    "    for idx, item in tqdm(enumerate(zip(imgs, keypoints))):\n",
    "        img, keypoint = item[0], item[1]\n",
    "\n",
    "        record = {}\n",
    "        filepath = os.path.join(train_dir, img)\n",
    "        record[\"height\"], record[\"width\"] = cv2.imread(filepath).shape[:2]\n",
    "        record[\"file_name\"] = filepath\n",
    "        record[\"image_id\"] = idx\n",
    "\n",
    "        keypoints_v = []\n",
    "        for i, keypoint_ in enumerate(keypoint):\n",
    "            keypoints_v.append(keypoint_) # if coco set, should be added 0.5\n",
    "            if i % 2 == 1:\n",
    "                keypoints_v.append(2)\n",
    "\n",
    "        x = keypoint[0::2]\n",
    "        y = keypoint[1::2]\n",
    "        x_min, x_max = min(x), max(x)\n",
    "        y_min, y_max = min(y), max(y)\n",
    "\n",
    "        obj = {\n",
    "            \"bbox\": [x_min, y_min, x_max, y_max],\n",
    "            \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "            \"category_id\": 0,\n",
    "            \"keypoints\": keypoints_v\n",
    "        }\n",
    "\n",
    "        record[\"annotations\"] = [obj]\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bibliographic-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "# aug_df = pd.read_csv(os.path.join(data_dir, \"augmented.csv\"))\n",
    "train_df = pd.read_csv(os.path.join(data_dir, \"train_df_modified.csv\"))\n",
    "\n",
    "keypoint_names = train_df.columns.to_list()[1:]\n",
    "keypoint_flip_map = []\n",
    "for i in range(0, len(keypoint_names) // 2, 2):\n",
    "    keypoint_flip_map.append((keypoint_names[i], keypoint_names[i+1]))\n",
    "\n",
    "columns = train_df.columns[1:].to_list()[::2]\n",
    "keypoint_names = [\n",
    "    label.replace(\"_x\", '').replace(\"_y\", '') for label in columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "packed-andrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata(evaluator_type='coco', keypoint_flip_map=[('nose_x', 'nose_y'), ('left_eye_x', 'left_eye_y'), ('right_eye_x', 'right_eye_y'), ('left_ear_x', 'left_ear_y'), ('right_ear_x', 'right_ear_y'), ('left_shoulder_x', 'left_shoulder_y'), ('right_shoulder_x', 'right_shoulder_y'), ('left_elbow_x', 'left_elbow_y'), ('right_elbow_x', 'right_elbow_y'), ('left_wrist_x', 'left_wrist_y'), ('right_wrist_x', 'right_wrist_y'), ('left_hip_x', 'left_hip_y')], keypoint_names=['nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear', 'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow', 'left_wrist', 'right_wrist', 'left_hip', 'right_hip', 'left_knee', 'right_knee', 'left_ankle', 'right_ankle', 'neck', 'left_palm', 'right_palm', 'spine2(back)', 'spine1(waist)', 'left_instep', 'right_instep'], name='keypoints_train', thing_classes=['human'])\n"
     ]
    }
   ],
   "source": [
    "imgs = train_df.iloc[:, 0].to_numpy()\n",
    "keypoints = train_df.iloc[:, 1:].to_numpy()\n",
    "imgs_train, imgs_val, keypoints_train, keypoints_val = \\\n",
    "    train_val_split(imgs, keypoints, random_state=42)\n",
    "\n",
    "imgs_d = {\n",
    "    \"train\": imgs_train,\n",
    "    \"val\": imgs_val\n",
    "}\n",
    "keypoints_d = {\n",
    "    \"train\": keypoints_train,\n",
    "    \"val\": keypoints_val\n",
    "}\n",
    "\n",
    "for d in [\"train\", \"val\"]:\n",
    "    DatasetCatalog.register(\n",
    "        \"keypoints_\" + d,\n",
    "        lambda d=d: get_data_dicts(\n",
    "            data_dir, imgs_d[d], keypoints_d[d], phase=d\n",
    "        )\n",
    "    )\n",
    "    MetadataCatalog.get(\"keypoints_\" + d).set(\n",
    "        thing_classes=[\"human\"]\n",
    "    )\n",
    "    MetadataCatalog.get(\"keypoints_\" + d).set(\n",
    "        keypoint_names=keypoint_names\n",
    "    )\n",
    "    MetadataCatalog.get(\"keypoints_\" + d).set(\n",
    "        keypoint_flip_map=keypoint_flip_map\n",
    "    )\n",
    "    MetadataCatalog.get(\"keypoints_\" + d).set(\n",
    "        evaluator_type=\"coco\"\n",
    "    )\n",
    "\n",
    "motions_metadata = MetadataCatalog.get(\"keypoints_train\")\n",
    "print(motions_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "exotic-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keypoint_rcnn_R_50_FPN_3x.yaml\n",
    "# keypoint_rcnn_X_101_32x8d_FPN_3x.yaml\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"keypoints_train\",)\n",
    "cfg.DATASETS.TEST = (\"keypoints_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 0\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "# cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.BASE_LR = 0.001  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 5000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []         # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_KEYPOINTS = 24\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "cfg.TEST.KEYPOINT_OKS_SIGMAS = kpt_oks_sigmas=np.ones((24, 1), dtype=float).tolist()\n",
    "cfg.TEST.EVAL_PERIOD = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "handy-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator = COCOEvaluator(\"keypoints_val\", (\"bbox\", \"keypoints\"), False, output_dir=\"./output/\", kpt_oks_sigmas=np.ones((24, 1), dtype=float).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "simplified-station",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/28 16:18:50 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (keypoint_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (keypoint_head): KRCNNConvDeconvUpsampleHead(\n",
      "      (conv_fcn1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn7): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_fcn8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (score_lowres): ConvTranspose2d(512, 24, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3679it [01:01, 60.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/28 16:19:51 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 3679 images left.\n",
      "\u001b[32m[03/28 16:19:51 d2.data.build]: \u001b[0mRemoved 0 images with fewer than 1 keypoints.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/28 16:19:51 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   human    | 3679         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[03/28 16:19:51 d2.data.common]: \u001b[0mSerializing 3679 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/28 16:19:52 d2.data.common]: \u001b[0mSerialized dataset takes 4.77 MiB\n",
      "\u001b[32m[03/28 16:19:52 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/28 16:19:52 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_5ad38f.pkl: 491MB [00:59, 8.18MB/s]                                                                                                                                               \n",
      "Skip loading parameter 'roi_heads.keypoint_head.score_lowres.weight' to the model due to incompatible shapes: (512, 17, 4, 4) in the checkpoint but (512, 24, 4, 4) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.keypoint_head.score_lowres.bias' to the model due to incompatible shapes: (17,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/28 16:20:52 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\layers\\wrappers.py:226: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n",
      "  return x.nonzero().unbind(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/28 16:21:24 d2.utils.events]: \u001b[0m eta: 2:09:17  iter: 19  total_loss: 8.397  loss_cls: 0.102  loss_box_reg: 0.106  loss_keypoint: 8.191  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 1.5395  data_time: 0.1172  lr: 0.000020  max_mem: 6231M\n",
      "\u001b[32m[03/28 16:21:55 d2.utils.events]: \u001b[0m eta: 2:08:36  iter: 39  total_loss: 8.323  loss_cls: 0.079  loss_box_reg: 0.106  loss_keypoint: 8.145  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 1.5376  data_time: 0.1176  lr: 0.000040  max_mem: 6231M\n",
      "\u001b[32m[03/28 16:22:27 d2.utils.events]: \u001b[0m eta: 2:08:17  iter: 59  total_loss: 8.218  loss_cls: 0.073  loss_box_reg: 0.080  loss_keypoint: 8.051  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 1.5517  data_time: 0.1156  lr: 0.000060  max_mem: 6231M\n",
      "\u001b[32m[03/28 16:22:57 d2.utils.events]: \u001b[0m eta: 2:07:34  iter: 79  total_loss: 8.131  loss_cls: 0.057  loss_box_reg: 0.082  loss_keypoint: 7.980  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 1.5385  data_time: 0.1104  lr: 0.000080  max_mem: 6231M\n",
      "\u001b[32m[03/28 16:23:27 d2.utils.events]: \u001b[0m eta: 2:06:52  iter: 99  total_loss: 8.021  loss_cls: 0.070  loss_box_reg: 0.073  loss_keypoint: 7.871  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 1.5296  data_time: 0.1114  lr: 0.000100  max_mem: 6231M\n",
      "\u001b[32m[03/28 16:23:57 d2.utils.events]: \u001b[0m eta: 2:06:21  iter: 119  total_loss: 7.840  loss_cls: 0.042  loss_box_reg: 0.047  loss_keypoint: 7.736  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 1.5290  data_time: 0.1112  lr: 0.000120  max_mem: 6231M\n",
      "\u001b[32m[03/28 16:24:28 d2.utils.events]: \u001b[0m eta: 2:05:56  iter: 139  total_loss: 7.628  loss_cls: 0.042  loss_box_reg: 0.042  loss_keypoint: 7.522  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.5314  data_time: 0.1106  lr: 0.000140  max_mem: 6231M\n",
      "\u001b[32m[03/28 16:24:59 d2.utils.events]: \u001b[0m eta: 2:05:24  iter: 159  total_loss: 7.245  loss_cls: 0.031  loss_box_reg: 0.038  loss_keypoint: 7.143  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.5306  data_time: 0.1104  lr: 0.000160  max_mem: 6231M\n",
      "\u001b[32m[03/28 16:25:29 d2.utils.events]: \u001b[0m eta: 2:04:58  iter: 179  total_loss: 6.610  loss_cls: 0.025  loss_box_reg: 0.047  loss_keypoint: 6.525  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 1.5313  data_time: 0.1121  lr: 0.000180  max_mem: 6282M\n",
      "\u001b[32m[03/28 16:26:00 d2.utils.events]: \u001b[0m eta: 2:04:23  iter: 199  total_loss: 5.936  loss_cls: 0.023  loss_box_reg: 0.026  loss_keypoint: 5.889  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.5294  data_time: 0.1101  lr: 0.000200  max_mem: 6282M\n",
      "\u001b[32m[03/28 16:26:29 d2.utils.events]: \u001b[0m eta: 2:03:52  iter: 219  total_loss: 5.438  loss_cls: 0.025  loss_box_reg: 0.030  loss_keypoint: 5.371  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.5258  data_time: 0.1089  lr: 0.000220  max_mem: 6282M\n",
      "\u001b[32m[03/28 16:27:00 d2.utils.events]: \u001b[0m eta: 2:03:29  iter: 239  total_loss: 5.105  loss_cls: 0.028  loss_box_reg: 0.035  loss_keypoint: 5.058  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.5260  data_time: 0.1112  lr: 0.000240  max_mem: 6282M\n",
      "\u001b[32m[03/28 16:27:30 d2.utils.events]: \u001b[0m eta: 2:02:58  iter: 259  total_loss: 4.841  loss_cls: 0.023  loss_box_reg: 0.032  loss_keypoint: 4.758  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.5247  data_time: 0.1099  lr: 0.000260  max_mem: 6282M\n",
      "\u001b[32m[03/28 16:28:00 d2.utils.events]: \u001b[0m eta: 2:02:18  iter: 279  total_loss: 4.605  loss_cls: 0.022  loss_box_reg: 0.024  loss_keypoint: 4.566  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 1.5239  data_time: 0.1101  lr: 0.000280  max_mem: 6282M\n",
      "\u001b[32m[03/28 16:28:31 d2.utils.events]: \u001b[0m eta: 2:01:43  iter: 299  total_loss: 4.525  loss_cls: 0.026  loss_box_reg: 0.021  loss_keypoint: 4.483  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.5229  data_time: 0.1104  lr: 0.000300  max_mem: 6282M\n",
      "\u001b[32m[03/28 16:28:59 d2.utils.events]: \u001b[0m eta: 2:01:09  iter: 319  total_loss: 4.432  loss_cls: 0.021  loss_box_reg: 0.028  loss_keypoint: 4.397  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.5163  data_time: 0.1070  lr: 0.000320  max_mem: 6282M\n",
      "\u001b[32m[03/28 16:29:29 d2.utils.events]: \u001b[0m eta: 2:00:38  iter: 339  total_loss: 4.291  loss_cls: 0.026  loss_box_reg: 0.023  loss_keypoint: 4.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 1.5162  data_time: 0.1087  lr: 0.000340  max_mem: 6282M\n",
      "\u001b[32m[03/28 16:30:00 d2.utils.events]: \u001b[0m eta: 2:00:07  iter: 359  total_loss: 4.425  loss_cls: 0.019  loss_box_reg: 0.020  loss_keypoint: 4.374  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.5162  data_time: 0.1138  lr: 0.000360  max_mem: 6282M\n",
      "\u001b[32m[03/28 16:30:29 d2.utils.events]: \u001b[0m eta: 1:59:36  iter: 379  total_loss: 4.219  loss_cls: 0.019  loss_box_reg: 0.024  loss_keypoint: 4.182  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 1.5147  data_time: 0.1113  lr: 0.000380  max_mem: 6308M\n",
      "\u001b[32m[03/28 16:30:59 d2.utils.events]: \u001b[0m eta: 1:59:05  iter: 399  total_loss: 4.252  loss_cls: 0.018  loss_box_reg: 0.027  loss_keypoint: 4.225  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.5129  data_time: 0.1122  lr: 0.000400  max_mem: 6308M\n",
      "\u001b[32m[03/28 16:31:29 d2.utils.events]: \u001b[0m eta: 1:58:34  iter: 419  total_loss: 4.093  loss_cls: 0.019  loss_box_reg: 0.024  loss_keypoint: 4.028  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 1.5118  data_time: 0.1111  lr: 0.000420  max_mem: 6308M\n",
      "\u001b[32m[03/28 16:31:59 d2.utils.events]: \u001b[0m eta: 1:58:03  iter: 439  total_loss: 4.226  loss_cls: 0.022  loss_box_reg: 0.030  loss_keypoint: 4.143  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.5110  data_time: 0.1119  lr: 0.000440  max_mem: 6308M\n",
      "\u001b[32m[03/28 16:32:30 d2.utils.events]: \u001b[0m eta: 1:57:32  iter: 459  total_loss: 4.081  loss_cls: 0.019  loss_box_reg: 0.024  loss_keypoint: 4.011  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 1.5125  data_time: 0.1102  lr: 0.000460  max_mem: 6308M\n",
      "\u001b[32m[03/28 16:33:00 d2.utils.events]: \u001b[0m eta: 1:57:02  iter: 479  total_loss: 4.134  loss_cls: 0.020  loss_box_reg: 0.024  loss_keypoint: 4.085  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 1.5131  data_time: 0.1118  lr: 0.000480  max_mem: 6325M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "516it [00:08, 60.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/28 16:33:39 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   human    | 516          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[03/28 16:33:39 d2.data.common]: \u001b[0mSerializing 516 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/28 16:33:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.67 MiB\n",
      "\u001b[32m[03/28 16:33:39 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[03/28 16:33:39 d2.evaluation.coco_evaluation]: \u001b[0m'keypoints_val' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
      "\u001b[32m[03/28 16:33:39 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'keypoints_val' to COCO format ...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "516it [00:06, 78.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/28 16:33:46 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/28 16:33:46 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 516, #annotations: 516\n",
      "\u001b[32m[03/28 16:33:46 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output\\inference\\keypoints_val_coco_format.json' ...\n",
      "\u001b[32m[03/28 16:33:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 516 images\n",
      "\u001b[32m[03/28 16:33:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/516. 0.2333 s / img. ETA=0:02:23\n",
      "\u001b[32m[03/28 16:33:54 d2.evaluation.evaluator]: \u001b[0mInference done 29/516. 0.2319 s / img. ETA=0:02:20\n",
      "\u001b[32m[03/28 16:33:59 d2.evaluation.evaluator]: \u001b[0mInference done 47/516. 0.2321 s / img. ETA=0:02:16\n",
      "\u001b[32m[03/28 16:34:05 d2.evaluation.evaluator]: \u001b[0mInference done 65/516. 0.2322 s / img. ETA=0:02:11\n",
      "\u001b[32m[03/28 16:34:10 d2.evaluation.evaluator]: \u001b[0mInference done 83/516. 0.2325 s / img. ETA=0:02:06\n",
      "\u001b[32m[03/28 16:34:15 d2.evaluation.evaluator]: \u001b[0mInference done 101/516. 0.2324 s / img. ETA=0:02:01\n",
      "\u001b[32m[03/28 16:34:20 d2.evaluation.evaluator]: \u001b[0mInference done 119/516. 0.2322 s / img. ETA=0:01:55\n",
      "\u001b[32m[03/28 16:34:26 d2.evaluation.evaluator]: \u001b[0mInference done 137/516. 0.2322 s / img. ETA=0:01:50\n",
      "\u001b[32m[03/28 16:34:31 d2.evaluation.evaluator]: \u001b[0mInference done 155/516. 0.2321 s / img. ETA=0:01:45\n",
      "\u001b[32m[03/28 16:34:36 d2.evaluation.evaluator]: \u001b[0mInference done 173/516. 0.2322 s / img. ETA=0:01:39\n",
      "\u001b[32m[03/28 16:34:41 d2.evaluation.evaluator]: \u001b[0mInference done 191/516. 0.2321 s / img. ETA=0:01:34\n",
      "\u001b[32m[03/28 16:34:47 d2.evaluation.evaluator]: \u001b[0mInference done 209/516. 0.2324 s / img. ETA=0:01:29\n",
      "\u001b[32m[03/28 16:34:52 d2.evaluation.evaluator]: \u001b[0mInference done 226/516. 0.2334 s / img. ETA=0:01:24\n",
      "\u001b[32m[03/28 16:34:57 d2.evaluation.evaluator]: \u001b[0mInference done 243/516. 0.2342 s / img. ETA=0:01:19\n",
      "\u001b[32m[03/28 16:35:02 d2.evaluation.evaluator]: \u001b[0mInference done 260/516. 0.2349 s / img. ETA=0:01:15\n",
      "\u001b[32m[03/28 16:35:07 d2.evaluation.evaluator]: \u001b[0mInference done 277/516. 0.2356 s / img. ETA=0:01:10\n",
      "\u001b[32m[03/28 16:35:12 d2.evaluation.evaluator]: \u001b[0mInference done 294/516. 0.2361 s / img. ETA=0:01:05\n",
      "\u001b[32m[03/28 16:35:18 d2.evaluation.evaluator]: \u001b[0mInference done 311/516. 0.2366 s / img. ETA=0:01:00\n",
      "\u001b[32m[03/28 16:35:23 d2.evaluation.evaluator]: \u001b[0mInference done 328/516. 0.2371 s / img. ETA=0:00:55\n",
      "\u001b[32m[03/28 16:35:28 d2.evaluation.evaluator]: \u001b[0mInference done 345/516. 0.2376 s / img. ETA=0:00:50\n",
      "\u001b[32m[03/28 16:35:33 d2.evaluation.evaluator]: \u001b[0mInference done 362/516. 0.2380 s / img. ETA=0:00:45\n",
      "\u001b[32m[03/28 16:35:38 d2.evaluation.evaluator]: \u001b[0mInference done 379/516. 0.2384 s / img. ETA=0:00:40\n",
      "\u001b[32m[03/28 16:35:43 d2.evaluation.evaluator]: \u001b[0mInference done 396/516. 0.2387 s / img. ETA=0:00:35\n",
      "\u001b[32m[03/28 16:35:49 d2.evaluation.evaluator]: \u001b[0mInference done 413/516. 0.2390 s / img. ETA=0:00:30\n",
      "\u001b[32m[03/28 16:35:54 d2.evaluation.evaluator]: \u001b[0mInference done 430/516. 0.2394 s / img. ETA=0:00:25\n",
      "\u001b[32m[03/28 16:35:59 d2.evaluation.evaluator]: \u001b[0mInference done 447/516. 0.2393 s / img. ETA=0:00:20\n",
      "\u001b[32m[03/28 16:36:04 d2.evaluation.evaluator]: \u001b[0mInference done 465/516. 0.2391 s / img. ETA=0:00:15\n",
      "\u001b[32m[03/28 16:36:09 d2.evaluation.evaluator]: \u001b[0mInference done 483/516. 0.2389 s / img. ETA=0:00:09\n",
      "\u001b[32m[03/28 16:36:15 d2.evaluation.evaluator]: \u001b[0mInference done 501/516. 0.2387 s / img. ETA=0:00:04\n",
      "\u001b[32m[03/28 16:36:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:31.829532 (0.297122 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/28 16:36:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:01 (0.238547 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/28 16:36:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/28 16:36:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output\\inference\\coco_instances_results.json\n",
      "\u001b[32m[03/28 16:36:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[4m\u001b[5m\u001b[31mERROR\u001b[0m \u001b[32m[03/28 16:36:19 d2.engine.train_loop]: \u001b[0mException during training:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\engine\\train_loop.py\", line 141, in train\n",
      "    self.after_step()\n",
      "  File \"d:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\engine\\train_loop.py\", line 162, in after_step\n",
      "    h.after_step()\n",
      "  File \"d:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\engine\\hooks.py\", line 349, in after_step\n",
      "    self._do_eval()\n",
      "  File \"d:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\engine\\hooks.py\", line 323, in _do_eval\n",
      "    results = self._func()\n",
      "  File \"d:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\engine\\defaults.py\", line 353, in test_and_save_results\n",
      "    self._last_eval_results = self.test(self.cfg, self.model)\n",
      "  File \"d:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\engine\\defaults.py\", line 517, in test\n",
      "    results_i = inference_on_dataset(model, data_loader, evaluator)\n",
      "  File \"d:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\evaluation\\evaluator.py\", line 176, in inference_on_dataset\n",
      "    results = evaluator.evaluate()\n",
      "  File \"d:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\evaluation\\coco_evaluation.py\", line 154, in evaluate\n",
      "    self._eval_predictions(set(self._tasks), predictions)\n",
      "  File \"d:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\evaluation\\coco_evaluation.py\", line 205, in _eval_predictions\n",
      "    if len(coco_results) > 0\n",
      "  File \"d:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\evaluation\\coco_evaluation.py\", line 515, in _evaluate_predictions_on_coco\n",
      "    coco_eval = (COCOeval_opt if use_fast_impl else COCOeval)(coco_gt, coco_dt, iou_type)\n",
      "  File \"C:\\Users\\hangjoo\\miniconda3\\envs\\daconEnv\\lib\\site-packages\\pycocotools\\cocoeval.py\", line 76, in __init__\n",
      "    self.params = Params(iouType=iouType) # parameters\n",
      "  File \"C:\\Users\\hangjoo\\miniconda3\\envs\\daconEnv\\lib\\site-packages\\pycocotools\\cocoeval.py\", line 527, in __init__\n",
      "    self.setDetParams()\n",
      "  File \"C:\\Users\\hangjoo\\miniconda3\\envs\\daconEnv\\lib\\site-packages\\pycocotools\\cocoeval.py\", line 507, in setDetParams\n",
      "    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n",
      "  File \"<__array_function__ internals>\", line 6, in linspace\n",
      "  File \"C:\\Users\\hangjoo\\miniconda3\\envs\\daconEnv\\lib\\site-packages\\numpy\\core\\function_base.py\", line 113, in linspace\n",
      "    num = operator.index(num)\n",
      "TypeError: 'numpy.float64' object cannot be interpreted as an integer\n",
      "\u001b[32m[03/28 16:36:19 d2.engine.hooks]: \u001b[0mOverall training speed: 497 iterations in 0:12:33 (1.5160 s / it)\n",
      "\u001b[32m[03/28 16:36:19 d2.engine.hooks]: \u001b[0mTotal training time: 0:15:22 (0:02:48 on hooks)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-6ffa4ec8dd3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# trainer.test(model=trainer.model, cfg=cfg, evaluators=evaluator)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\engine\\defaults.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[0mOrderedDict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0menabled\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mOtherwise\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \"\"\"\n\u001b[1;32m--> 400\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXPECTED_RESULTS\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcomm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             assert hasattr(\n",
      "\u001b[1;32md:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\engine\\train_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[0;32m    139\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Exception during training:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\engine\\train_loop.py\u001b[0m in \u001b[0;36mafter_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mafter_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m         \u001b[1;31m# this guarantees, that in each hook's after_step, storage.iter == trainer.iter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\engine\\hooks.py\u001b[0m in \u001b[0;36mafter_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[0mis_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_iter\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_final\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_period\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnext_iter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_period\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mafter_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\engine\\hooks.py\u001b[0m in \u001b[0;36m_do_eval\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\engine\\defaults.py\u001b[0m in \u001b[0;36mtest_and_save_results\u001b[1;34m()\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mtest_and_save_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_eval_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_eval_results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\engine\\defaults.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(cls, cfg, model, evaluators)\u001b[0m\n\u001b[0;32m    515\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mresults_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minference_on_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcomm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\evaluation\\evaluator.py\u001b[0m in \u001b[0;36minference_on_dataset\u001b[1;34m(model, data_loader, evaluator)\u001b[0m\n\u001b[0;32m    174\u001b[0m     )\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[1;31m# An evaluator may return None when not in main process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# Replace it by an empty dict instead to make it easier for downstream code to handle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\evaluation\\coco_evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eval_box_proposals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"instances\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eval_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[1;31m# Copy so the caller can do whatever with results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\evaluation\\coco_evaluation.py\u001b[0m in \u001b[0;36m_eval_predictions\u001b[1;34m(self, tasks, predictions)\u001b[0m\n\u001b[0;32m    203\u001b[0m                     \u001b[0muse_fast_impl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_fast_impl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m                 )\n\u001b[1;32m--> 205\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoco_results\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m                 \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# cocoapi does not handle empty results very well\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             )\n",
      "\u001b[1;32md:\\develop\\projects\\dacon_motion_key_point_detection\\ver2\\detectron2-windows\\detectron2\\evaluation\\coco_evaluation.py\u001b[0m in \u001b[0;36m_evaluate_predictions_on_coco\u001b[1;34m(coco_gt, coco_results, iou_type, kpt_oks_sigmas, use_fast_impl)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[0mcoco_dt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoco_gt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadRes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoco_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m     \u001b[0mcoco_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mCOCOeval_opt\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0muse_fast_impl\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mCOCOeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoco_gt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoco_dt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miou_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0miou_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"keypoints\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\daconEnv\\lib\\site-packages\\pycocotools\\cocoeval.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, cocoGt, cocoDt, iouType)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m# gt for evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m# dt for evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miouType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miouType\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_paramsEval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m               \u001b[1;31m# parameters for evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m                     \u001b[1;31m# result summarization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\daconEnv\\lib\\site-packages\\pycocotools\\cocoeval.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, iouType)\u001b[0m\n\u001b[0;32m    525\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miouType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'segm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0miouType\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'segm'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miouType\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'bbox'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetDetParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0miouType\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'keypoints'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetKpParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\daconEnv\\lib\\site-packages\\pycocotools\\cocoeval.py\u001b[0m in \u001b[0;36msetDetParams\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatIds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[1;31m# np.arange causes trouble.  the data point on arange is slightly larger than the true value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miouThrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.95\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.95\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m.05\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecThrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.00\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.00\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m.0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m.01\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxDets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mlinspace\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\daconEnv\\lib\\site-packages\\numpy\\core\\function_base.py\u001b[0m in \u001b[0;36mlinspace\u001b[1;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \"\"\"\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of samples, %s, must be non-negative.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "# trainer.test(model=trainer.model, cfg=cfg, evaluators=evaluator)\n",
    "\n",
    "# trainer.test(cfg, trainer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stuffed-johnston",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1600/1600 [08:11<00:00,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "preds = []\n",
    "files = []\n",
    "test_dir = os.path.join(data_dir, \"test_imgs\")\n",
    "test_list = os.listdir(test_dir)\n",
    "test_list.sort()\n",
    "except_list = []\n",
    "for file in tqdm(test_list):\n",
    "    filepath = os.path.join(test_dir, file)\n",
    "    # print(filepath)\n",
    "    im = cv2.imread(filepath)\n",
    "    outputs = predictor(im)\n",
    "    outputs = outputs[\"instances\"].to(\"cpu\").get(\"pred_keypoints\").numpy()\n",
    "    files.append(file)\n",
    "    pred = []\n",
    "    try:\n",
    "        for out in outputs[0]:\n",
    "            pred.extend([float(e) for e in out[:2]])\n",
    "    except:\n",
    "        except_list.append(filepath)\n",
    "        print(filepath)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dried-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv(f\"../data/sample_submission.csv\")\n",
    "df = pd.DataFrame(columns=df_sub.columns)\n",
    "df[\"image\"] = files\n",
    "df.iloc[:, 1:] = preds\n",
    "\n",
    "df.to_csv(f\"submissions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-preparation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
